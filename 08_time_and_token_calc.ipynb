{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from _stat_gen import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt_method(method: str) -> str:\n",
    "    if \"CoT\" in method:\n",
    "        return \"CoT\"\n",
    "    elif \"IP\" in method or \"IPO\" in method:\n",
    "        return \"IP\"\n",
    "    else:\n",
    "        return \"None\"\n",
    "\n",
    "def get_model_type(model: str) -> str:\n",
    "    if \"claude\" in model:\n",
    "        return \"Commercial\"\n",
    "    else:\n",
    "        return \"Local\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "local_history_directory = 'local_chat_history'\n",
    "csv_files = [f for f in os.listdir(local_history_directory) if f.endswith('.csv')]\n",
    "csv_files\n",
    "\n",
    "ag_df = pd.DataFrame()\n",
    "for csv in csv_files:\n",
    "    print(f\"Processing {csv}...\")\n",
    "    df = pd.read_csv('local_chat_history/'+csv)\n",
    "    # df = df.tail(3900)  # Limit to the first 1000 rows\n",
    "    df['token_count'] = df['reason'].apply(lambda x: count_tokens(x) if pd.notnull(x) else 0)\n",
    "\n",
    "    df.drop(columns=['accession_number', 'question', 'answer', 'reason', 'model_name'], inplace=True)\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "    df = df.sort_values(\"timestamp\")\n",
    "    df =df.head(975)\n",
    "    \n",
    "\n",
    "    df[\"Time_Diff_Seconds\"] = df[\"timestamp\"].diff().dt.total_seconds()\n",
    "\n",
    "    # Drop the first row as it has NaN time diff\n",
    "    time_diffs = df[\"Time_Diff_Seconds\"].dropna()\n",
    "\n",
    "    token_calc = df['token_count'].dropna()\n",
    "\n",
    "    combined_stats = {\n",
    "    \"Model Name\": csv.replace('.csv', ''),\n",
    "    'Model Type': get_model_type(csv),\n",
    "    \"Prompt Method\": get_prompt_method(csv),\n",
    "    \"Max Time Diff\": time_diffs.max(),\n",
    "    \"Min Time Diff\": time_diffs.min(),\n",
    "    \"Mean Time Diff\": round(time_diffs.mean(), 2),\n",
    "    \"Std Dev Time Diff\": round(time_diffs.std(), 2),\n",
    "    \"Max Tokens\": token_calc.max(),\n",
    "    \"Min Tokens\": token_calc.min(),\n",
    "    \"Mean Tokens\": round(token_calc.mean(), 2),\n",
    "    \"Std Dev Tokens\": round(token_calc.std(), 2),\n",
    "    }\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    combined_stats_df = pd.DataFrame([combined_stats])\n",
    "    ag_df = pd.concat([ag_df, combined_stats_df], ignore_index=True)\n",
    "    # print(combined_stats_df)\n",
    "\n",
    "\n",
    "ag_df = ag_df.sort_values(\"Prompt Method\", ascending=False)\n",
    "ag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_models = \"Qwen|Claude\"\n",
    "main_paper_table_df = ag_df[ag_df['Model Name'].str.contains(winner_models)]\n",
    "main_paper_table_df = main_paper_table_df.sort_values(\"Model Type\", ascending=False)\n",
    "main_paper_table_df.to_csv('paper-tables/main_paper_table.csv', index=False)\n",
    "\n",
    "# cols_to_merge = ['Model Name', 'Model Type']\n",
    "# main_paper_table_df = apply_multirow(main_paper_table_df, cols_to_merge)\n",
    "\n",
    "main_paper_table_df_latex = main_paper_table_df.to_latex(index=False, escape=False,  float_format=\"%.2f\")\n",
    "print(main_paper_table_df_latex)\n",
    "main_paper_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appendix_df = ag_df[~ag_df['Model Name'].str.contains(winner_models)]\n",
    "appendix_df = appendix_df.groupby('Model Name').apply(\n",
    "    lambda group: group.sort_values('Prompt Method', ascending=False)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "cols_to_merge = ['Model Name']\n",
    "appendix_df = apply_multirow(appendix_df, cols_to_merge)\n",
    "\n",
    "\n",
    "appendix_df_latex = appendix_df.to_latex(index=False, escape=False, float_format=\"%.2f\" )\n",
    "print(appendix_df_latex)\n",
    "appendix_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
